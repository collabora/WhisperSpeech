{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdbe3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp prepare_s2a_atoks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf56fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbdddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from fastprogress import progress_bar\n",
    "from fastcore.script import *\n",
    "\n",
    "import webdataset as wds\n",
    "from whisperspeech import utils, vad_merge\n",
    "from whisperspeech.inference import get_compute_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d80d3b",
   "metadata": {},
   "source": [
    "# S2A dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1a5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def load_model():\n",
    "    \"Load the pretrained EnCodec model\"\n",
    "    from encodec.model import EncodecModel\n",
    "    model = EncodecModel.encodec_model_24khz()\n",
    "    model.set_target_bandwidth(1.5)\n",
    "    model.to(get_compute_device()).eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f271d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@call_parse\n",
    "def prepare_atoks(\n",
    "    input:str,  # audio file webdataset file path\n",
    "    output:str, # output shard path\n",
    "    n_samples:int=None, # process a limited amount of samples\n",
    "    batch_size:int=4, # process several segments at once\n",
    "    bandwidth:float=3,\n",
    "):\n",
    "    device = get_compute_device()\n",
    "    amodel = load_model().to(device)  # Move model to computed device\n",
    "    amodel.set_target_bandwidth(bandwidth)\n",
    "\n",
    "    total = n_samples//batch_size if n_samples else 'noinfer'\n",
    "    if n_samples: print(f\"Benchmarking run of {n_samples} samples ({total} batches)\")\n",
    "\n",
    "    if total == 'noinfer':\n",
    "        import math, time\n",
    "        start = time.time()\n",
    "        ds = wds.WebDataset([utils.derived_name(input, 'mvad')]).decode()\n",
    "        total = math.ceil(sum([len(x['max.spk_emb.npy']) for x in ds])/batch_size)\n",
    "        print(f\"Counting {total} batches: {time.time()-start:.2f}\")\n",
    "\n",
    "    ds = vad_merge.chunked_audio_dataset([input], 'max').compose(\n",
    "        utils.resampler(24000, 'samples_24k'),\n",
    "        wds.to_tuple('__key__', 'rpad_s', 'samples_24k'),\n",
    "        wds.batched(64),\n",
    "    )\n",
    "\n",
    "    dl = wds.WebLoader(ds, num_workers=1, batch_size=None).unbatched().batched(batch_size)\n",
    "\n",
    "    with utils.AtomicTarWriter(output, throwaway=n_samples is not None) as sink:\n",
    "        for keys, rpad_ss, samples in progress_bar(dl, total=total):\n",
    "            csamples = samples.to(device).unsqueeze(1)  # Move tensors to computed device\n",
    "            atokss = amodel.encode(csamples)[0][0]\n",
    "            atokss = atokss.cpu().numpy().astype(np.int16)\n",
    "            for key, rpad_s, atoks in zip(keys, rpad_ss, atokss):\n",
    "                atoks = atoks[:,:int((30-rpad_s) * 75 + 0.5)]\n",
    "                sink.write({\n",
    "                    \"__key__\": key,\n",
    "                    \"atoks.npy\": atoks,\n",
    "                })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
