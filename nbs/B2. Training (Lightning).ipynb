{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afd7255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp train_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e79ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "from fastprogress import progress_bar, master_bar\n",
    "import fastprogress\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.profiler import record_function\n",
    "from whisperspeech import utils, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232153f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "import lightning.pytorch as pl\n",
    "import math\n",
    "\n",
    "class TrainingTask(pl.LightningModule):\n",
    "    def __init__(self, model, model_hparams=None):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.model_hparams = model_hparams\n",
    "        \n",
    "    def on_fit_start(self):\n",
    "        if getattr(self.model, 'setup'):\n",
    "            self.model.setup(self.device)\n",
    "        if self.model_hparams['torch_compile'] and getattr(self.model, 'optimize_training'):\n",
    "            import torch._dynamo\n",
    "            torch._dynamo.config.optimize_ddp = False\n",
    "            # FIXME: define a batch of dummy tensors in the model\n",
    "            testing.test_model(model, train_dss[0], bs=batch_size)\n",
    "            model.optimize_training()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        \"\"\" Initialize AdamW optimizer\"\"\"\n",
    "        lr = self.model_hparams['lr0']\n",
    "        weight_decay = self.model_hparams['weight_decay']\n",
    "        \n",
    "        all_params = set(model.parameters())\n",
    "        customized_params = set()\n",
    "        groups = []\n",
    "        group_map = {}\n",
    "        for name,m in model.named_modules():\n",
    "            if hasattr(m, 'no_weight_decay') or hasattr(m, 'lr_scale'):\n",
    "                customized_params |= set(m.parameters())\n",
    "                m_wd = 0 if hasattr(m, 'no_weight_decay') else weight_decay\n",
    "                m_lr = lr * getattr(m, 'lr_scale', 1)\n",
    "                group = group_map.get((m_wd, m_lr), None)\n",
    "                if not group:\n",
    "                    group = {\"params\": [], \"names\": [], \"weight_decay\": m_wd, \"lr\": m_lr}\n",
    "                    groups.append(group)\n",
    "                    group_map[(m_wd, m_lr)] = group\n",
    "                group['params'] += m.parameters()\n",
    "                group['names'].append(name)\n",
    "                \n",
    "        other_params = all_params - customized_params\n",
    "        \n",
    "        param_groups = groups + [\n",
    "            {\"names\": [\"other\"], \"params\": list(other_params), \"weight_decay\": weight_decay },\n",
    "        ]\n",
    "\n",
    "        optimizer = torch.optim.AdamW(lr=lr, betas=(0.9, 0.95), params=param_groups)\n",
    "        \n",
    "        # modified from https://github.com/Lightning-AI/lightning/issues/5449#issuecomment-1501597319\n",
    "        def num_steps_per_epoch() -> int:\n",
    "            \"\"\"Get number of steps\"\"\"\n",
    "            # Accessing _data_source is flaky and might break\n",
    "            dataset = self.trainer.fit_loop._data_source.dataloader()\n",
    "            dataset_size = len(dataset)\n",
    "            # math.ceil so always overestimate (underestimating throws exceptions)\n",
    "            num_steps = math.ceil(dataset_size / self.trainer.accumulate_grad_batches)\n",
    "            return num_steps\n",
    "        \n",
    "        warmup_steps = self.model_hparams['warmup_steps']\n",
    "        total_steps = self.model_hparams['iterations']\n",
    "        self.model_hparams['pct_start'] = min(0.3, warmup_steps / total_steps)\n",
    "\n",
    "        print(f\"{self.model_hparams['iterations']=} steps\")\n",
    "\n",
    "        if self.model_hparams['lr_schedule'] == 'cosine':\n",
    "            lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "                optimizer,\n",
    "                pct_start=self.model_hparams['pct_start'],\n",
    "                max_lr=[pg.get('lr', lr) for pg in param_groups],\n",
    "                steps_per_epoch=num_steps_per_epoch(),\n",
    "                epochs=1,\n",
    "                final_div_factor=25\n",
    "            )\n",
    "        elif self.model_hparams['lr_schedule'] == 'linear':\n",
    "            warmup_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "                optimizer, 1e-3, 1, warmup_steps\n",
    "            )\n",
    "            train_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "                optimizer, 1, 1/25, total_steps - warmup_steps\n",
    "            )\n",
    "            lr_scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
    "                optimizer, schedulers=[warmup_scheduler, train_scheduler], milestones=[warmup_steps]\n",
    "            )\n",
    "        elif self.model_hparams['lr_schedule'] == 'wsd':\n",
    "            warmup_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "                optimizer, 1e-3, 1, warmup_steps\n",
    "            )\n",
    "            train_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "                optimizer, [int(total_steps - warmup_steps - 0.1*total_steps)], 1/8,\n",
    "            )\n",
    "            lr_scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
    "                optimizer, schedulers=[warmup_scheduler, train_scheduler], milestones=[warmup_steps]\n",
    "            )\n",
    "        else:\n",
    "            raise Exception(\"Unknown learning rate schedule\")\n",
    "\n",
    "        return [optimizer], [{'scheduler': lr_scheduler, 'interval': 'step'}]\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        train_out = self.model.forward(*train_batch)\n",
    "        train_loss = train_out[-1]\n",
    "\n",
    "        self.log(\"train_loss\", train_loss, sync_dist=True)\n",
    "        return train_loss\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx, dataloader_idx=0):\n",
    "        val_out = self.model.forward(*val_batch)\n",
    "        val_loss = val_out[-1]\n",
    "\n",
    "        name = val_dss_names[dataloader_idx]\n",
    "        self.log(f\"val_loss/{name}\", val_loss.detach(), sync_dist=True, add_dataloader_idx=False)\n",
    "        if hasattr(self.model, 'get_metrics'):\n",
    "            self.log_dict({f'metrics/{k}_{name}':v for k,v in self.model.get_metrics().items()}, sync_dist=True, add_dataloader_idx=False)\n",
    "        return val_loss.detach()\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        for name, weight in zip(train_dss_names, train_weights):\n",
    "            self.log(f\"trainer/{name}-batches\", weight.to(self.device) * self.global_step, sync_dist=True)\n",
    "    \n",
    "    def test_step(self, val_batch, batch_idx):\n",
    "        test_out = self.model.forward(*val_batch)\n",
    "        test_loss = test_out[-1]\n",
    "\n",
    "        self.log(\"test_loss\", test_loss, sync_dist=True)\n",
    "        return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae232d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "from fastcore.script import anno_parser\n",
    "import shlex\n",
    "\n",
    "# watch out: we can only pass Python values as keyword arguments (not positional)\n",
    "# everything else has to be a string\n",
    "def parse_and_call(name, fun, args, kwargs={}, log_to_wandb=True):\n",
    "    print(f\"Parsing arguments for {name}, {args}\")\n",
    "    p = anno_parser(fun, prog=name)\n",
    "    args = p.parse_args(args).__dict__\n",
    "    args.pop('xtra'); args.pop('pdb')\n",
    "    args.update({k:v for k, v in kwargs.items()})\n",
    "    if log_to_wandb and type(wandb_logger.experiment.config) == wandb.sdk.wandb_config.Config:\n",
    "        wandb_logger.experiment.config[name] = {k:v for k,v in args.items() if k not in ['dataset', 'tunables']}\n",
    "    return fun(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b23790e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] 4 False\n"
     ]
    }
   ],
   "source": [
    "def test_fun(a:str=None, to:int = 2, toggle:bool=True):\n",
    "    assert(a is not None)\n",
    "    print(a, to, toggle)\n",
    "parse_and_call(\"test\", test_fun, [\"--to\", \"4\"], dict(a=[]), log_to_wandb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8ac45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 2 True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Namespace(a=None, to=2, toggle=False, pdb=False, xtra=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastcore.script import anno_parser\n",
    "def test_fun(a:str=None, to:int = 2, toggle:bool=True):\n",
    "    assert(a is not None)\n",
    "    print(a, to, toggle)\n",
    "test_fun(\"a\")\n",
    "anno_parser(test_fun).parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd039c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwe 2\n"
     ]
    }
   ],
   "source": [
    "def test_fun2(a:str, to:int = 2):\n",
    "    assert(a is not None)\n",
    "    print(a, to)\n",
    "\n",
    "parse_and_call(\"test\", test_fun2, [\"qwe\"], log_to_wandb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7ec1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "# split only full path components to stabilize the names\n",
    "def simplify_folder_names(lst):\n",
    "    lst = [x.strip('/') for x in lst] # normalize pathnames, removing trailing and leading slashes\n",
    "    parts = [x.split('/') for x in lst]\n",
    "    prefix = os.path.commonprefix(parts)\n",
    "    suffix = os.path.commonprefix([x[::-1] for x in parts])\n",
    "    print(prefix, suffix)\n",
    "    return ['_'.join(x[len(prefix):len(x)-len(suffix)]) for x in parts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9474199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['youtube-cc', 'mls-spanish']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# strip path suffixes (useful for validation splits)\n",
    "simplify_folder_names(['/data2/youtube-cc/txt-random-valid', '/data2/mls-spanish/txt-random-valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3dd26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mls-spanish', 'mls-polish']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# strip path prefixes but only full folders\n",
    "simplify_folder_names(['/data2/mls-spanish', '/data2/mls-polish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7822542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--task', type=str, help='Task to train')\n",
    "parser.add_argument('--seed', type=int, default=0, help='Global training seed')\n",
    "parser.add_argument('--batch-size', type=int, default=16, help='total batch size for all GPUs')\n",
    "parser.add_argument('--workers', type=int, default=8, help='max dataloader workers (per RANK in DDP mode)')\n",
    "parser.add_argument('--input-dir', type=str, default='', help='input data path') # fixed in the model for now\n",
    "parser.add_argument('--dataset-config', type=str, default='', help='common dataset options')\n",
    "parser.add_argument('--training-data', action='append', type=str, default=[], help='training dataset')\n",
    "parser.add_argument('--validation-data', action='append', type=str, default=[], help='validation dataset (can be passed multiple times)')\n",
    "parser.add_argument('--monitored-metric', type=str, default=\"val_loss\", help='metric to monitor for checkpointing')\n",
    "parser.add_argument(\"--checkpoint-dir\", type=str, default=\"./checkpoints/\", help=\"directory to save the checkpoints\")\n",
    "parser.add_argument('--iterations', type=int, default=8000, help='total training iterations')\n",
    "parser.add_argument('--validate-every-n-steps', type=int, default=500, help='how training steps to run between validations')\n",
    "parser.add_argument('--weight-decay', type=float, default=1e-2, help='optimizer weight decay')\n",
    "parser.add_argument('--lr0', type=float, default=1e-4, help='optimizer initial learning rate')\n",
    "parser.add_argument('--lr-schedule', type=str, default=\"cosine\", help='the learning rate schedule [cosine, linear or wsd]')\n",
    "parser.add_argument('--clip-gradient-norm', type=float, default=None, help='enable gradient norm clipping')\n",
    "parser.add_argument('--accumulate-grad-batches', type=int, default=1, help='perform the optimizer step only after going through several batches of samples')\n",
    "parser.add_argument('--precision', type=str, default=\"16-mixed\", help=\"floating point precision\")\n",
    "parser.add_argument('--torch-compile', type=bool, default=False, help='compile (parts of) the model with torch.compile')\n",
    "parser.add_argument('--warmup-steps', type=int, default=10000, help='total number steps during which the learning rate rises (defaults to 10k updates)')\n",
    "parser.add_argument('--tunables', type=str, default=\"\", help='tunable hyperparameters')\n",
    "parser.add_argument('--resume-from', type=Path, default=None, help='resume training from the given checkpoint')\n",
    "parser.add_argument('--load-from', type=Path, default=None, help='initialize the weights from the given model')\n",
    "parser.add_argument('--strategy', type=str, default='ddp', help='distributed training strategy')\n",
    "parser.add_argument('--wandb-suffix', type=str, default=None, help='W&B project name suffix')\n",
    "parser.add_argument('--wandb-task-name', type=str, default=None, help='Task name for the W&B project name')\n",
    "\n",
    "args = parser.parse_args().__dict__\n",
    "\n",
    "task_args: list = shlex.split(args.pop(\"task\"))\n",
    "task_name, task_args = task_args[0], task_args[1:]\n",
    "input_args: list = shlex.split(args.pop(\"input_dir\"))\n",
    "dataset_config: list = shlex.split(args.pop(\"dataset_config\"))\n",
    "monitored_metric: str = args.pop(\"monitored_metric\")\n",
    "checkpoint_dir: str = args.pop(\"checkpoint_dir\")\n",
    "num_workers: int = args.pop(\"workers\")\n",
    "batch_size: int = args.pop(\"batch_size\")\n",
    "iterations: int = args.pop(\"iterations\")\n",
    "tunables_args: list = shlex.split(args.pop(\"tunables\"))\n",
    "\n",
    "hyp_params = {}\n",
    "hyp_params['batch_size'] = batch_size\n",
    "hyp_params['warmup_steps'] = args['warmup_steps']\n",
    "hyp_params['weight_decay'] = args['weight_decay']\n",
    "hyp_params['clip_gradient_norm'] = args['clip_gradient_norm']\n",
    "hyp_params['accumulate_grad_batches'] = args['accumulate_grad_batches']\n",
    "hyp_params['validate_every_n_steps'] = args[\"validate_every_n_steps\"]\n",
    "hyp_params['precision'] = args['precision']\n",
    "hyp_params['torch_compile'] = args['torch_compile']\n",
    "hyp_params['lr0'] = args['lr0']\n",
    "hyp_params['lr_schedule'] = args['lr_schedule']\n",
    "hyp_params['iterations'] = iterations\n",
    "hyp_params['strategy'] = args['strategy']\n",
    "if 'SLURM_NTASKS' in os.environ:\n",
    "    hyp_params['world_size'] = os.environ['SLURM_NTASKS']\n",
    "else:\n",
    "    hyp_params['world_size'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e8af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def parse_dataset_string(s):\n",
    "    cwd = [None]\n",
    "    def load_file_reference(matchobj):\n",
    "        fname = matchobj.group(1)\n",
    "        cwd[0] = Path(fname).parent\n",
    "        if fname.startswith('http://') or fname.startswith('https://'):\n",
    "            response = requests.get(target_url)\n",
    "            return response.text.strip()\n",
    "        else:\n",
    "            with open(fname, 'r') as f:\n",
    "                return f.read().strip()\n",
    "    s = re.sub('@([^ ]+)', load_file_reference, s)\n",
    "    arg_list = shlex.split(s)\n",
    "    if cwd[0]: arg_list += ['--cwd', str(cwd[0])]\n",
    "    return arg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a224add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "from lightning.fabric.utilities.rank_zero import rank_zero_only\n",
    "import datetime\n",
    "import webdataset as wds\n",
    "import importlib\n",
    "import dataclasses\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "project = f\"WhisperSpeech-{args['wandb_task_name'] or task_name}\"\n",
    "if args['wandb_suffix']:\n",
    "    project += \"-\"+args['wandb_suffix']\n",
    "\n",
    "from faker import Faker\n",
    "fake = Faker()\n",
    "name = (fake.name().split()[0] + \"_\" + fake.color_name()).lower()\n",
    "\n",
    "if rank_zero_only.rank == 0:\n",
    "    print('Experiment name:', name)\n",
    "wandb_logger = WandbLogger(project=project, name=name)\n",
    "\n",
    "ckpt_callback = pl.callbacks.ModelCheckpoint(\n",
    "     dirpath=f'{task_name}',\n",
    "     filename=f'{task_name}-{name}'+\"-{step}-acc={\"+monitored_metric+\":.2f}\",\n",
    "     monitor=monitored_metric,\n",
    "     save_top_k=16,\n",
    "     train_time_interval=datetime.timedelta(minutes=14),\n",
    "     auto_insert_metric_name=False\n",
    ")\n",
    "\n",
    "lr_monitor_callback = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "task = importlib.import_module(\"whisperspeech.\"+task_name)\n",
    "\n",
    "# load all training sets\n",
    "train_dss = [parse_and_call(f'train_ds_{i}', task.load_dataset,\n",
    "                            parse_dataset_string(train_ds_config) + dataset_config)\n",
    "             for i,train_ds_config in enumerate(args['training_data'])]\n",
    "train_dss_names = simplify_folder_names([parse_dataset_string(train_ds_config)[0] for train_ds_config in args['training_data']])\n",
    "print('train names:', train_dss_names)\n",
    "counts = [x.total_samples for x in train_dss]\n",
    "print(counts)\n",
    "print(torch.tensor(counts).log2())\n",
    "train_weights = torch.tensor(counts).log2() - torch.tensor(counts).log2().min() + 1\n",
    "for tds, w in zip(train_dss, train_weights):\n",
    "    tds.weight = w\n",
    "\n",
    "train_total_batches = hyp_params['iterations']\n",
    "if train_total_batches < hyp_params['validate_every_n_steps']:\n",
    "    # validate once at the end of every epoch for very short experiments\n",
    "    hyp_params['validate_every_n_steps'] = train_total_batches\n",
    "\n",
    "# persistent_workers=True is critical here so we don't reset the sample shuffling buffers\n",
    "# with webdatasets sample shuffling is very bad initially, unless num_workers << num_shards\n",
    "train_loader = wds.WebLoader(\n",
    "    utils.join_datasets(train_dss),\n",
    "    num_workers=num_workers, drop_last=False, batch_size=None, shuffle=False, persistent_workers=num_workers > 0,\n",
    ").unbatched().shuffle(1024).batched(batch_size).with_length(train_total_batches)\n",
    "\n",
    "# load all validation sets\n",
    "val_dss_names = [parse_dataset_string(val_ds_config)[0] for val_ds_config in args['validation_data']]\n",
    "val_dss_names = simplify_folder_names(val_dss_names)\n",
    "print('validation names:', val_dss_names)\n",
    "\n",
    "val_dss = [parse_and_call(f'val_ds_{i}', task.load_dataset,\n",
    "                          parse_dataset_string(val_ds_config) + dataset_config, {'validation': True})\n",
    "           for i,val_ds_config in enumerate(args['validation_data'])]\n",
    "val_loaders = [wds.WebLoader(\n",
    "        val_ds, num_workers=num_workers, drop_last=False, batch_size=None, shuffle=False,\n",
    "    ).unbatched().batched(batch_size).with_length(val_ds.total_samples // batch_size)\n",
    "   for val_ds in val_dss]\n",
    "\n",
    "tunables = None\n",
    "if hasattr(task, \"Tunables\"):\n",
    "    tunables = parse_and_call('tunables', task.Tunables, tunables_args, log_to_wandb=False)\n",
    "    # override command line args from the tunables object\n",
    "    for k in [\"lr0\", \"clip_gradient_norm\", \"weight_decay\", \"warmup_steps\"]:\n",
    "        val = getattr(tunables, k, None)\n",
    "        if val is not None: hyp_params[k] = val\n",
    "    \n",
    "    if type(wandb_logger.experiment.config) == wandb.sdk.wandb_config.Config:\n",
    "        wandb_logger.experiment.config['tunables'] = dataclasses.asdict(tunables)\n",
    "\n",
    "trainer = pl.Trainer(strategy=hyp_params['strategy'],\n",
    "                  max_steps=hyp_params['iterations'],\n",
    "                  accelerator=\"gpu\",\n",
    "                  profiler=\"simple\",\n",
    "                  precision=hyp_params['precision'],\n",
    "                  gradient_clip_val=hyp_params['clip_gradient_norm'],\n",
    "                  accumulate_grad_batches=hyp_params['accumulate_grad_batches'],\n",
    "                  val_check_interval=hyp_params['validate_every_n_steps'],\n",
    "                  check_val_every_n_epoch=None,\n",
    "                  enable_checkpointing=True,\n",
    "                  logger=wandb_logger,\n",
    "                  num_nodes=int(os.environ.get('SLURM_NNODES', 1)),\n",
    "                  devices=int(os.environ.get('SLURM_NTASKS_PER_NODE', 1)),\n",
    "                  callbacks=[ckpt_callback, lr_monitor_callback])\n",
    "        \n",
    "# we initialize everything manually anyways\n",
    "with trainer.init_module(empty_init=True):\n",
    "    if args['load_from']:\n",
    "        model = task.load_model(str(args['load_from']))\n",
    "    else:\n",
    "        model_kwargs = dict(dataset=train_dss[0])\n",
    "        if tunables is not None: model_kwargs['tunables'] = tunables\n",
    "        model = parse_and_call('model', task.make_model, task_args, model_kwargs)\n",
    "\n",
    "if type(wandb_logger.experiment.config) == wandb.sdk.wandb_config.Config:\n",
    "    wandb_logger.experiment.config.update(hyp_params)\n",
    "    \n",
    "kwargs = {}\n",
    "if 'resume_from' in args:\n",
    "    kwargs['ckpt_path'] = args['resume_from']\n",
    "trainer.fit(model=TrainingTask(model, model_hparams=hyp_params),\n",
    "            train_dataloaders=train_loader,\n",
    "            val_dataloaders=val_loaders,\n",
    "            **kwargs)\n",
    "\n",
    "if rank_zero_only.rank == 0:\n",
    "    Path(task_name).mkdir(exist_ok=True, parents=True)\n",
    "    fname = f'{task_name}/{name}.model'\n",
    "    print('Saving:', fname)\n",
    "    model.save_model(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00406652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffffe92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
