{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdbe3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp prepare_t2s_txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf56fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbdddfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "/opt/conda/lib/python3.10/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from fastprogress import progress_bar\n",
    "from fastcore.script import *\n",
    "\n",
    "import whisper, whisperx\n",
    "from whisperspeech import utils, vad_merge\n",
    "import webdataset as wds\n",
    "\n",
    "from whisperspeech.inference import get_compute_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d80d3b",
   "metadata": {},
   "source": [
    "# T2S dataset preparation\n",
    "\n",
    "We take a webdataset shard and extract semantic tokens and transcriptions from it.\n",
    "\n",
    "We use VAD chunks merged with randomized maximum length to also generate some short samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8bf372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class Transcriber:\n",
    "    \"\"\"\n",
    "    A helper class to transcribe a batch of 30 second audio chunks.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_size, lang=False):\n",
    "        self.model = whisperx.asr.load_model(\n",
    "            model_size, get_compute_device(), compute_type=\"float16\", language=lang,\n",
    "            asr_options=dict(repetition_penalty=1, no_repeat_ngram_size=0, prompt_reset_on_temperature=0.5,\n",
    "                             max_new_tokens=500, clip_timestamps=None, hallucination_silence_threshold=None))\n",
    "        # without calling vad_model at least once the rest segfaults for some reason...\n",
    "        self.model.vad_model({\"waveform\": torch.zeros(1, 16000), \"sample_rate\": 16000})\n",
    "        \n",
    "    def transcribe(self, batch):\n",
    "        batch = whisper.log_mel_spectrogram(batch)\n",
    "        embs = self.model.model.encode(batch.cpu().numpy())\n",
    "        return self.model.tokenizer.tokenizer.decode_batch([x.sequences_ids[0] for x in \n",
    "            self.model.model.model.generate(\n",
    "                embs,\n",
    "                [self.model.model.get_prompt(self.model.tokenizer, [], without_timestamps=True)]*len(batch),\n",
    "            )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f271d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@call_parse\n",
    "def prepare_txt(\n",
    "    input:str,  # FLAC webdataset file path (or - to read the names from stdin)\n",
    "    n_samples:int=None, # process a limited amount of samples\n",
    "    batch_size:int=1, # process several segments at once\n",
    "    transcription_model:str=\"small.en\",\n",
    "    language:str=False,\n",
    "    skip_first_and_last:bool=False,\n",
    "):\n",
    "    transcriber = Transcriber(transcription_model, lang=language)\n",
    "#     whmodel = whisper.load_model(transcription_model)\n",
    "#     decoding_options = whisper.DecodingOptions(language=language)\n",
    "#     for b in whmodel.decoder.blocks:\n",
    "#         b.attn.qkv_attention = b.attn.qkv_attention_old\n",
    "\n",
    "    total = n_samples//batch_size if n_samples else 'noinfer'\n",
    "    if n_samples: print(f\"Benchmarking run of {n_samples} samples ({total} batches)\")\n",
    "\n",
    "    ds = vad_merge.chunked_audio_dataset([input], 'eqvad').compose(\n",
    "        utils.resampler(16000, 'samples_16k'),\n",
    "    )\n",
    "    \n",
    "    if skip_first_and_last:\n",
    "        # when processing LibriLight we drop the first and last segment because they tend\n",
    "        # to be inaccurate (the transcriptions lack the \"LibriVox ad\" prefixes and\n",
    "        # \"end of chapter\" suffixes)\n",
    "        ds = ds.compose(\n",
    "            wds.select(lambda x: x['i'] != 0 and x['i'] != x['imax']),\n",
    "        )\n",
    "    \n",
    "    ds = ds.compose(\n",
    "        wds.to_tuple('__key__', 'rpad', 'samples_16k'),\n",
    "        wds.batched(64),\n",
    "    )\n",
    "\n",
    "    dl = wds.WebLoader(ds, num_workers=1, batch_size=None).unbatched().batched(batch_size)\n",
    "\n",
    "    with utils.AtomicTarWriter(utils.derived_name(input, f'{transcription_model}-txt', dir=\".\"), throwaway=n_samples is not None) as sink:\n",
    "        for keys, rpads, samples in progress_bar(dl, total=total):\n",
    "            csamples = samples.to(get_compute_device())\n",
    "            txts = transcriber.transcribe(csamples)\n",
    "            # with torch.no_grad():\n",
    "            #     embs = whmodel.encoder(whisper.log_mel_spectrogram(csamples))\n",
    "            #     decs = whmodel.decode(embs, decoding_options)\n",
    "            #     txts = [x.text for x in decs]\n",
    "\n",
    "            for key, rpad, txt in zip(keys, rpads, txts):\n",
    "                sink.write({\n",
    "                    \"__key__\": key,\n",
    "                    \"txt\": txt,\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff3c278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.1.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.1.0+cu121. Bad things might happen unless you revert torch to 1.x.\n",
      "Benchmarking run of 1024 samples (64 batches)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='64' class='' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [64/64 00:40&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prepare_txt('../wolnelektury-wds2/wolnelektury-audio-000000.tar', n_samples=1024, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05cfbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking run of 1024 samples (64 batches)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='64' class='' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [64/64 01:33&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "prepare_txt('../wolnelektury-wds2/wolnelektury-audio-000000.tar', n_samples=1024, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79a459c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking run of 1024 samples (64 batches)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='64' class='' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [64/64 02:06&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "prepare_txt('../wolnelektury-wds2/wolnelektury-audio-000000.tar', transcription_model='medium', n_samples=1024, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fa8ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking run of 1024 samples (1024 batches)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='1024' class='' max='1024' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1024/1024 10:01&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "prepare_txt('../wolnelektury-wds2/wolnelektury-audio-000000.tar', transcription_model='medium', n_samples=1024, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b66e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ace212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
